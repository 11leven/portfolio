{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "import nltk\n",
        "import re\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer=SnowballStemmer('english')\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count":1,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df=pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
        "df.head()"
      ],
      "execution_count":7,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>Product Name<\/th>\n",
              "      <th>Brand Name<\/th>\n",
              "      <th>Price<\/th>\n",
              "      <th>Rating<\/th>\n",
              "      <th>Reviews<\/th>\n",
              "      <th>Review Votes<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0<\/th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...<\/td>\n",
              "      <td>Samsung<\/td>\n",
              "      <td>199.99<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...<\/td>\n",
              "      <td>1.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>1<\/th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...<\/td>\n",
              "      <td>Samsung<\/td>\n",
              "      <td>199.99<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>2<\/th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...<\/td>\n",
              "      <td>Samsung<\/td>\n",
              "      <td>199.99<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>Very pleased<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>3<\/th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...<\/td>\n",
              "      <td>Samsung<\/td>\n",
              "      <td>199.99<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>It works good but it goes slow sometimes but i...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>4<\/th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...<\/td>\n",
              "      <td>Samsung<\/td>\n",
              "      <td>199.99<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>Great phone to replace my lost phone. The only...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df=df[['Reviews','Rating']]"
      ],
      "execution_count":9,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df=df.dropna()\n",
        "df.info()"
      ],
      "execution_count":10,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 413778 entries, 0 to 413839\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Reviews  413778 non-null  object\n",
            " 1   Rating   413778 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 9.5+ MB\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df=df[df['Rating']!=3]\n",
        "df.info()"
      ],
      "execution_count":11,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 382015 entries, 0 to 413839\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Reviews  382015 non-null  object\n",
            " 1   Rating   382015 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 8.7+ MB\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df=df.reset_index(drop=True)\n",
        "df.info()"
      ],
      "execution_count":12,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 382015 entries, 0 to 382014\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Reviews  382015 non-null  object\n",
            " 1   Rating   382015 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 5.8+ MB\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df['sentiment']=np.where(df['Rating'] > 3, 1, 0)\n",
        "df.head()"
      ],
      "execution_count":13,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>Reviews<\/th>\n",
              "      <th>Rating<\/th>\n",
              "      <th>sentiment<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0<\/th>\n",
              "      <td>I feel so LUCKY to have found this used (phone...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>1<\/th>\n",
              "      <td>nice phone, nice up grade from my pantach revu...<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>1<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>2<\/th>\n",
              "      <td>Very pleased<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>3<\/th>\n",
              "      <td>It works good but it goes slow sometimes but i...<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>1<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>4<\/th>\n",
              "      <td>Great phone to replace my lost phone. The only...<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>1<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count":17,
      "outputs":[
        {
          "name":"stderr",
          "text":[
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     \/home\/datalore\/nltk_data...\n",
            "[nltk_data]   Unzipping corpora\/stopwords.zip.\n"
          ],
          "output_type":"stream"
        },
        {
          "data":{
            "text\/plain":[
              "True"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "Cstopwords=set(stopwords.words('english')+list(punctuation))\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma=WordNetLemmatizer()"
      ],
      "execution_count":18,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def clean_review(review_column):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_column)):\n",
        "        review=review_column[i]\n",
        "        #review=BeautifulSoup(review,'lxml').text\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        review=str(review).lower()\n",
        "        review=word_tokenize(review)\n",
        "        #review=[stemmer.stem(w) for w in review if w not in Cstopwords]\n",
        "        review=[lemma.lemmatize(w) for w in review ]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "    return review_corpus"
      ],
      "execution_count":19,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count":24,
      "outputs":[
        {
          "name":"stderr",
          "text":[
            "[nltk_data] Downloading package punkt to \/home\/datalore\/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to \/home\/datalore\/nltk_data...\n",
            "[nltk_data]   Unzipping corpora\/wordnet.zip.\n"
          ],
          "output_type":"stream"
        },
        {
          "data":{
            "text\/plain":[
              "True"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "review_column=df['Reviews']\n",
        "review_corpus=clean_review(review_column)"
      ],
      "execution_count":25,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df['clean_review']=review_corpus\n",
        "df.tail(20)"
      ],
      "execution_count":26,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>Reviews<\/th>\n",
              "      <th>Rating<\/th>\n",
              "      <th>sentiment<\/th>\n",
              "      <th>clean_review<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>381995<\/th>\n",
              "      <td>This phone is simple, very good , and it works...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>this phone is simple very good and it work exc...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>381996<\/th>\n",
              "      <td>Good sturdy phone for a pre-teen to have avail...<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>good sturdy phone for a pre teen to have avail...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>381997<\/th>\n",
              "      <td>This is the second junk Convoy I have owned. T...<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>this is the second junk convoy i have owned th...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>381998<\/th>\n",
              "      <td>I BOUGHT THIS PHONE FOR MY HUSBAND AND HE LOVE...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>i bought this phone for my husband and he love...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>381999<\/th>\n",
              "      <td>They said phone was normal wear but it was a l...<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>they said phone wa normal wear but it wa a lie...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382000<\/th>\n",
              "      <td>You could shoot this out of a potato gun, and ...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>you could shoot this out of a potato gun and p...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382001<\/th>\n",
              "      <td>Bought this for my mother and she loves it. Gr...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>bought this for my mother and she love it grea...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382002<\/th>\n",
              "      <td>Excellent phone, as advertised. Love the push-...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>excellent phone a advertised love the push to ...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382003<\/th>\n",
              "      <td>works great and picks up signal in place my ot...<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>work great and pick up signal in place my othe...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382004<\/th>\n",
              "      <td>Great phone. Large keys, best flip phone I hav...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>great phone large key best flip phone i have o...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382005<\/th>\n",
              "      <td>Pros...Works great, very durable, easy to navi...<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>pro work great very durable easy to navigate s...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382006<\/th>\n",
              "      <td>just as described perfect for the price<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>just a described perfect for the price<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382007<\/th>\n",
              "      <td>Would not work<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>would not work<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382008<\/th>\n",
              "      <td>LOVE IT<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>love it<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382009<\/th>\n",
              "      <td>Item was listed as new, but was not. When we t...<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>item wa listed a new but wa not when we tried ...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382010<\/th>\n",
              "      <td>good rugged phone that has a long-lasting batt...<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>good rugged phone that ha a long lasting batte...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382011<\/th>\n",
              "      <td>used hard<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>used hard<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382012<\/th>\n",
              "      <td>another great deal great price<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>another great deal great price<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382013<\/th>\n",
              "      <td>Passes every drop test onto porcelain tile!<\/td>\n",
              "      <td>5<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>pass every drop test onto porcelain tile<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>382014<\/th>\n",
              "      <td>Only downside is that apparently Verizon no lo...<\/td>\n",
              "      <td>4<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>only downside is that apparently verizon no lo...<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count":27,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "cv=CountVectorizer(max_features=20000,min_df=5,ngram_range=(1,2))"
      ],
      "execution_count":29,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X1=cv.fit_transform(df['clean_review'])\n",
        "X1.shape"
      ],
      "execution_count":30,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "(382015, 20000)"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count":31,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tfidf=TfidfVectorizer(min_df=5, max_df=0.95, max_features = 20000, ngram_range = ( 1, 2 ),\n",
        "                              sublinear_tf = True)"
      ],
      "execution_count":32,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tfidf=tfidf.fit(df['clean_review'])"
      ],
      "execution_count":33,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X2=tfidf.transform(df['clean_review'])\n",
        "X2.shape"
      ],
      "execution_count":34,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "(382015, 20000)"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "y=df['sentiment'].values\n",
        "y.shape"
      ],
      "execution_count":35,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "(382015,)"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=0)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count":37,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "(305612, 20000) (305612,)\n",
            "(76403, 20000) (76403,)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# average positive reviews in train and test\n",
        "print('mean positive review in train : {0:.3f}'.format(np.mean(y_train)))\n",
        "print('mean positive review in test : {0:.3f}'.format(np.mean(y_test)))"
      ],
      "execution_count":38,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "mean positive review in train : 0.746\n",
            "mean positive review in test : 0.745\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.linear_model import LogisticRegression as lr"
      ],
      "execution_count":39,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "model_lr=lr(random_state=0)"
      ],
      "execution_count":40,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "%%time\n",
        "model_lr=lr(penalty='l2',C=1.0,random_state=0)\n",
        "model_lr.fit(X_train,y_train)\n",
        "y_pred_lr=model_lr.predict(X_test)\n",
        "print('accuracy for Logistic Regression :',accuracy_score(y_test,y_pred_lr))\n",
        "print('confusion matrix for Logistic Regression:\\n',confusion_matrix(y_test,y_pred_lr))\n",
        "print('F1 score for Logistic Regression :',f1_score(y_test,y_pred_lr))\n",
        "print('Precision score for Logistic Regression :',precision_score(y_test,y_pred_lr))\n",
        "print('recall score for Logistic Regression :',recall_score(y_test,y_pred_lr))\n",
        "print('AUC: ', roc_auc_score(y_test, y_pred_lr))"
      ],
      "execution_count":41,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "accuracy for Logistic Regression : 0.963273693441357\n",
            "confusion matrix for Logistic Regression:\n",
            " [[17786  1679]\n",
            " [ 1127 55811]]\n",
            "F1 score for Logistic Regression : 0.9754780298528333\n",
            "Precision score for Logistic Regression : 0.970794920855801\n",
            "recall score for Logistic Regression : 0.9802065404475043\n",
            "AUC:  0.9469745776987073\n",
            "CPU times: user 15.1 s, sys: 7.18 s, total: 22.3 s\n",
            "Wall time: 11.6 s\n"
          ],
          "output_type":"stream"
        },
        {
          "name":"stderr",
          "text":[
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/linear_model\/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https:\/\/scikit-learn.org\/stable\/modules\/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# get the feature names as numpy array\n",
        "feature_names = np.array(cv.get_feature_names())\n",
        "\n",
        "# Sort the coefficients from the model\n",
        "sorted_coef_index = model_lr.coef_[0].argsort()\n",
        "\n",
        "# Find the 10 smallest and 10 largest coefficients\n",
        "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
        "# so the list returned is in order of largest to smallest\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
      ],
      "execution_count":44,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Smallest Coefs:\n",
            "['not happy' 'not satisfied' 'no good' 'not worth' 'worst' 'garbage'\n",
            " 'awful' 'junk' 'not good' 'not very']\n",
            "\n",
            "Largest Coefs: \n",
            "['excelent' 'excelente' 'exelente' 'not bad' 'excellent' 'no issue'\n",
            " 'perfect' 'perfecto' 'awesome' 'great']\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model_nb=MultinomialNB()\n",
        "model_nb.fit(X_train,y_train)\n",
        "y_pred_nb=model_nb.predict(X_test)\n",
        "print('accuracy for Naive Bayes Classifier :',accuracy_score(y_test,y_pred_nb))\n",
        "print('confusion matrix for Naive Bayes Classifier:\\n',confusion_matrix(y_test,y_pred_nb))\n",
        "print('F1 score for Logistic Regression :',f1_score(y_test,y_pred_nb))\n",
        "print('Precision score for Logistic Regression :',precision_score(y_test,y_pred_nb))\n",
        "print('recall score for Logistic Regression :',recall_score(y_test,y_pred_nb))\n",
        "print('AUC: ', roc_auc_score(y_test, y_pred_nb))"
      ],
      "execution_count":45,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "accuracy for Naive Bayes Classifier : 0.93337957933589\n",
            "confusion matrix for Naive Bayes Classifier:\n",
            " [[17047  2418]\n",
            " [ 2672 54266]]\n",
            "F1 score for Logistic Regression : 0.9552023375754695\n",
            "Precision score for Logistic Regression : 0.957342459953426\n",
            "recall score for Logistic Regression : 0.9530717622677298\n",
            "AUC:  0.9144243989864208\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# get the feature names as numpy array\n",
        "feature_names = np.array(cv.get_feature_names())\n",
        "\n",
        "# Sort the coefficients from the model\n",
        "sorted_coef_index = model_nb.coef_[0].argsort()\n",
        "\n",
        "# Find the 10 smallest and 10 largest coefficients\n",
        "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
        "# so the list returned is in order of largest to smallest\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
      ],
      "execution_count":46,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Smallest Coefs:\n",
            "['worst purchase' 'nothing work' 'zero star' 'reported stolen'\n",
            " 'never recommend' 'royalty' 'total waste' 'or refund' 'is scam'\n",
            " 'went completely']\n",
            "\n",
            "Largest Coefs: \n",
            "['the' 'it' 'phone' 'and' 'to' 'is' 'this' 'for' 'my' 'with']\n"
          ],
          "output_type":"stream"
        },
        {
          "name":"stderr",
          "text":[
            "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/utils\/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count":47,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "%%time\n",
        "model_rf=RandomForestClassifier()\n",
        "model_rf.fit(X_train,y_train)\n",
        "y_pred_rf=model_rf.predict(X_test)\n",
        "print('accuracy for Random Forest Classifier :',accuracy_score(y_test,y_pred_rf))\n",
        "print('confusion matrix for Random Forest Classifier:\\n',confusion_matrix(y_test,y_pred_rf))"
      ],
      "execution_count":48,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "accuracy for Random Forest Classifier : 0.9767941049435231\n",
            "confusion matrix for Random Forest Classifier:\n",
            " [[18245  1220]\n",
            " [  553 56385]]\n",
            "CPU times: user 48min 17s, sys: 3.97 s, total: 48min 21s\n",
            "Wall time: 48min 20s\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# get the feature names as numpy array\n",
        "feature_names = np.array(cv.get_feature_names())\n",
        "\n",
        "# Sort the coefficients from the model\n",
        "sorted_coef_index = model_rf.feature_importances_.argsort()\n",
        "\n",
        "# Find the 10 smallest and 10 largest coefficients\n",
        "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
        "# so the list returned is in order of largest to smallest\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
      ],
      "execution_count":49,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Smallest Coefs:\n",
            "['safari' 'not tested' 'image stabilization' 'pixel density'\n",
            " 'watching youtube' 'smooth the' 'very crisp' 'with update' 'me away'\n",
            " 'toggle']\n",
            "\n",
            "Largest Coefs: \n",
            "['not' 'great' 'love' 'return' 'the' 'bad' 'good' 'excellent' 'after'\n",
            " 'month']\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "execution_count":0,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}